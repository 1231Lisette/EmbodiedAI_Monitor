import os
import yaml
import logging
import requests
import smtplib
from datetime import datetime
from email.mime.text import MIMEText
from email.header import Header
from email.utils import formataddr
from src.database import Database
from src.scrapers import ArxivScraper, GithubScraper, HuggingFaceScraper
from src.llm_agent import LLMAgent
from src.processor import Processor
import json # ç¡®ä¿å¯¼å…¥ json

# æ—¥å¿—é…ç½®
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

def send_email_notification(config, content):
    """å‘é€é‚®ä»¶æ¨é€"""
    email_conf = config.get('notification', {}).get('email', {})
    if not config.get('notification', {}).get('enabled'):
        return

    sender = email_conf.get('sender')
    password = email_conf.get('password')
    receiver = email_conf.get('receiver')
    smtp_server = email_conf.get('smtp_server')
    smtp_port = email_conf.get('smtp_port')

    if not all([sender, password, receiver, smtp_server, smtp_port]):
        logger.error("é‚®ä»¶é…ç½®ä¸å®Œæ•´ï¼Œæ— æ³•å‘é€æ¨é€")
        return

    # æ„å»ºé‚®ä»¶
    subject = f"ğŸ¤– Embodied AI æ—¥æŠ¥ - {len(content.splitlines())//4} æ¡ç²¾é€‰"
    message = MIMEText(content, 'plain', 'utf-8')
    
    # ä½¿ç”¨ formataddr ç”Ÿæˆç¬¦åˆ RFC æ ‡å‡†çš„å¤´éƒ¨
    message['From'] = formataddr(["AI Monitor", sender])
    message['To'] = formataddr(["Researcher", receiver])
    message['Subject'] = Header(subject, 'utf-8')

    try:
        logger.info("æ­£åœ¨å‘é€é‚®ä»¶...")
        if smtp_port == 465:
            server = smtplib.SMTP_SSL(smtp_server, smtp_port)
        else:
            server = smtplib.SMTP(smtp_server, smtp_port)
            server.starttls()
        
        server.login(sender, password)
        server.sendmail(sender, [receiver], message.as_string())
        server.quit()
        logger.info("âœ… é‚®ä»¶å‘é€æˆåŠŸï¼è¯·æ£€æŸ¥æ”¶ä»¶ç®±")
    except Exception as e:
        logger.error(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")

def main():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.join(base_dir, 'config.yaml')
    
    if not os.path.exists(config_path):
        logger.error("æ‰¾ä¸åˆ° config.yamlï¼")
        return

    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    db = Database()
    llm = LLMAgent(config)
    tagger = Processor()

    items_to_process = []

    # 1. æŠ“å– (ArXiv)
    logger.info("ğŸš€ å¼€å§‹æŠ“å– ArXiv...")
    for p in ArxivScraper(config).scrape():
        p['type'] = 'papers'
        items_to_process.append(p)

    # 2. æŠ“å– (GitHub)
    logger.info("ğŸš€ å¼€å§‹æŠ“å– GitHub...")
    for p in GithubScraper(config).scrape():
        p['type'] = 'projects'
        # GitHub é¢„è§ˆå›¾
        p['media_url'] = f"https://opengraph.githubassets.com/1/{p['id'].replace('github:', '')}"
        items_to_process.append(p)

    # 3. æŠ“å– (Hugging Face)
    logger.info("ğŸš€ å¼€å§‹æŠ“å– Hugging Face...")
    for p in HuggingFaceScraper(config).scrape():
        p['type'] = 'models'
        items_to_process.append(p)

    # 4. AI å®¡ç¨¿
    logger.info(f"ğŸ§  AI æ­£åœ¨è¯„å®¡ {len(items_to_process)} æ¡å†…å®¹...")
    
    all_tags = set()

    for item in items_to_process:
        # ç”Ÿæˆæ ‡ç­¾
        item['tags'] = tagger.generate_tags(item['title'], item['abstract'])
        for t in item['tags']:
            all_tags.add(t)
        
        # è°ƒç”¨ LLM æ‰“åˆ†
        score, comment = llm.review_item(item['title'], item['abstract'], item['source'])
        item['ai_score'] = score
        item['ai_comment'] = comment
        
        print(f"   [{score}åˆ†] {item['title'][:40]}... | {comment}")
        
        # å­˜å…¥æ•°æ®åº“
        db.upsert_item(item)

    # 5. ç”Ÿæˆæ—¥æŠ¥å¹¶æ¨é€
    top_items = db.fetch_items(min_score=6) 
    
    if top_items:
        logger.info(f"æ‰¾åˆ° {len(top_items)} æ¡é«˜åˆ†å†…å®¹ï¼Œå‡†å¤‡ç”Ÿæˆæ—¥æŠ¥...")
        report = llm.generate_daily_report(top_items)
        send_email_notification(config, report)
    else:
        logger.info("ä»Šæ—¥æ²¡æœ‰é«˜åˆ†å†…å®¹ï¼Œä¸æ‰“æ‰°äº†ã€‚")
        
    # 6. ç”Ÿæˆ JS æ•°æ®æ–‡ä»¶
    items_to_process.sort(key=lambda x: x.get('ai_score', 0), reverse=True)
    
    daily_summary_text = report if 'report' in locals() else "ä»Šæ—¥æ— é«˜åˆ†æ›´æ–°"
    
    # --- ä¿®å¤éƒ¨åˆ†ï¼šå…ˆå¤„ç†å­—ç¬¦ä¸²ï¼Œå†æ”¾å…¥ f-string ---
    safe_summary = daily_summary_text.replace('"', '\\"').replace('\n', '\\n')
    
    js_content = f"""
    window.RESEARCH_DATA = {json.dumps(items_to_process, ensure_ascii=False)};
    window.ALL_TAGS = {json.dumps(list(all_tags), ensure_ascii=False)};
    window.DAILY_SUMMARY = "{safe_summary}";
    window.LAST_UPDATE = "{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}";
    """
    
    web_dir = os.path.join(base_dir, 'web')
    os.makedirs(web_dir, exist_ok=True)
    with open(os.path.join(web_dir, 'data.js'), 'w', encoding='utf-8') as f:
        f.write(js_content)
    
    db.close()
    logger.info("ğŸ‰ ä»»åŠ¡å®Œæˆï¼")

if __name__ == "__main__":
    main()